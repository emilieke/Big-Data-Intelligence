{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. SOME PRELIMINARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Emilie/Dropbox/Skole/UC3M/Machine Learning/Assignment 2 part 2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import matplotlib.pyplot as plt \n",
    "# For plotting data\n",
    "import numpy as np              \n",
    "# For Panda dataframes. A dataframe is a matrix-like structure, \n",
    "# similar to R dataframes  \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The \"wind_pickle\" file contains data in a binary format called \"Pickle\". Pickle data loads faster than text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('wind_pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the attributes in the dataset. Very important, the output attribute (i.e. the value to be predicted, **energy**, is the first attribute). **Steps** represents the hours in advance of the forecast. We will not use this variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 556)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['energy',\n",
       " 'steps',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'p54.162.1',\n",
       " 'p54.162.2',\n",
       " 'p54.162.3',\n",
       " 'p54.162.4',\n",
       " 'p54.162.5',\n",
       " 'p54.162.6',\n",
       " 'p54.162.7',\n",
       " 'p54.162.8',\n",
       " 'p54.162.9',\n",
       " 'p54.162.10',\n",
       " 'p54.162.11',\n",
       " 'p54.162.12',\n",
       " 'p54.162.13',\n",
       " 'p54.162.14',\n",
       " 'p54.162.15',\n",
       " 'p54.162.16',\n",
       " 'p54.162.17',\n",
       " 'p54.162.18',\n",
       " 'p54.162.19',\n",
       " 'p54.162.20',\n",
       " 'p54.162.21',\n",
       " 'p54.162.22',\n",
       " 'p54.162.23',\n",
       " 'p54.162.24',\n",
       " 'p54.162.25',\n",
       " 'p55.162.1',\n",
       " 'p55.162.2',\n",
       " 'p55.162.3',\n",
       " 'p55.162.4',\n",
       " 'p55.162.5',\n",
       " 'p55.162.6',\n",
       " 'p55.162.7',\n",
       " 'p55.162.8',\n",
       " 'p55.162.9',\n",
       " 'p55.162.10',\n",
       " 'p55.162.11',\n",
       " 'p55.162.12',\n",
       " 'p55.162.13',\n",
       " 'p55.162.14',\n",
       " 'p55.162.15',\n",
       " 'p55.162.16',\n",
       " 'p55.162.17',\n",
       " 'p55.162.18',\n",
       " 'p55.162.19',\n",
       " 'p55.162.20',\n",
       " 'p55.162.21',\n",
       " 'p55.162.22',\n",
       " 'p55.162.23',\n",
       " 'p55.162.24',\n",
       " 'p55.162.25',\n",
       " 'cape.1',\n",
       " 'cape.2',\n",
       " 'cape.3',\n",
       " 'cape.4',\n",
       " 'cape.5',\n",
       " 'cape.6',\n",
       " 'cape.7',\n",
       " 'cape.8',\n",
       " 'cape.9',\n",
       " 'cape.10',\n",
       " 'cape.11',\n",
       " 'cape.12',\n",
       " 'cape.13',\n",
       " 'cape.14',\n",
       " 'cape.15',\n",
       " 'cape.16',\n",
       " 'cape.17',\n",
       " 'cape.18',\n",
       " 'cape.19',\n",
       " 'cape.20',\n",
       " 'cape.21',\n",
       " 'cape.22',\n",
       " 'cape.23',\n",
       " 'cape.24',\n",
       " 'cape.25',\n",
       " 'p59.162.1',\n",
       " 'p59.162.2',\n",
       " 'p59.162.3',\n",
       " 'p59.162.4',\n",
       " 'p59.162.5',\n",
       " 'p59.162.6',\n",
       " 'p59.162.7',\n",
       " 'p59.162.8',\n",
       " 'p59.162.9',\n",
       " 'p59.162.10',\n",
       " 'p59.162.11',\n",
       " 'p59.162.12',\n",
       " 'p59.162.13',\n",
       " 'p59.162.14',\n",
       " 'p59.162.15',\n",
       " 'p59.162.16',\n",
       " 'p59.162.17',\n",
       " 'p59.162.18',\n",
       " 'p59.162.19',\n",
       " 'p59.162.20',\n",
       " 'p59.162.21',\n",
       " 'p59.162.22',\n",
       " 'p59.162.23',\n",
       " 'p59.162.24',\n",
       " 'p59.162.25',\n",
       " 'lai_lv.1',\n",
       " 'lai_lv.2',\n",
       " 'lai_lv.3',\n",
       " 'lai_lv.4',\n",
       " 'lai_lv.5',\n",
       " 'lai_lv.6',\n",
       " 'lai_lv.7',\n",
       " 'lai_lv.8',\n",
       " 'lai_lv.9',\n",
       " 'lai_lv.10',\n",
       " 'lai_lv.11',\n",
       " 'lai_lv.12',\n",
       " 'lai_lv.13',\n",
       " 'lai_lv.14',\n",
       " 'lai_lv.15',\n",
       " 'lai_lv.16',\n",
       " 'lai_lv.17',\n",
       " 'lai_lv.18',\n",
       " 'lai_lv.19',\n",
       " 'lai_lv.20',\n",
       " 'lai_lv.21',\n",
       " 'lai_lv.22',\n",
       " 'lai_lv.23',\n",
       " 'lai_lv.24',\n",
       " 'lai_lv.25',\n",
       " 'lai_hv.1',\n",
       " 'lai_hv.2',\n",
       " 'lai_hv.3',\n",
       " 'lai_hv.4',\n",
       " 'lai_hv.5',\n",
       " 'lai_hv.6',\n",
       " 'lai_hv.7',\n",
       " 'lai_hv.8',\n",
       " 'lai_hv.9',\n",
       " 'lai_hv.10',\n",
       " 'lai_hv.11',\n",
       " 'lai_hv.12',\n",
       " 'lai_hv.13',\n",
       " 'lai_hv.14',\n",
       " 'lai_hv.15',\n",
       " 'lai_hv.16',\n",
       " 'lai_hv.17',\n",
       " 'lai_hv.18',\n",
       " 'lai_hv.19',\n",
       " 'lai_hv.20',\n",
       " 'lai_hv.21',\n",
       " 'lai_hv.22',\n",
       " 'lai_hv.23',\n",
       " 'lai_hv.24',\n",
       " 'lai_hv.25',\n",
       " 'u10n.1',\n",
       " 'u10n.2',\n",
       " 'u10n.3',\n",
       " 'u10n.4',\n",
       " 'u10n.5',\n",
       " 'u10n.6',\n",
       " 'u10n.7',\n",
       " 'u10n.8',\n",
       " 'u10n.9',\n",
       " 'u10n.10',\n",
       " 'u10n.11',\n",
       " 'u10n.12',\n",
       " 'u10n.13',\n",
       " 'u10n.14',\n",
       " 'u10n.15',\n",
       " 'u10n.16',\n",
       " 'u10n.17',\n",
       " 'u10n.18',\n",
       " 'u10n.19',\n",
       " 'u10n.20',\n",
       " 'u10n.21',\n",
       " 'u10n.22',\n",
       " 'u10n.23',\n",
       " 'u10n.24',\n",
       " 'u10n.25',\n",
       " 'v10n.1',\n",
       " 'v10n.2',\n",
       " 'v10n.3',\n",
       " 'v10n.4',\n",
       " 'v10n.5',\n",
       " 'v10n.6',\n",
       " 'v10n.7',\n",
       " 'v10n.8',\n",
       " 'v10n.9',\n",
       " 'v10n.10',\n",
       " 'v10n.11',\n",
       " 'v10n.12',\n",
       " 'v10n.13',\n",
       " 'v10n.14',\n",
       " 'v10n.15',\n",
       " 'v10n.16',\n",
       " 'v10n.17',\n",
       " 'v10n.18',\n",
       " 'v10n.19',\n",
       " 'v10n.20',\n",
       " 'v10n.21',\n",
       " 'v10n.22',\n",
       " 'v10n.23',\n",
       " 'v10n.24',\n",
       " 'v10n.25',\n",
       " 'sp.1',\n",
       " 'sp.2',\n",
       " 'sp.3',\n",
       " 'sp.4',\n",
       " 'sp.5',\n",
       " 'sp.6',\n",
       " 'sp.7',\n",
       " 'sp.8',\n",
       " 'sp.9',\n",
       " 'sp.10',\n",
       " 'sp.11',\n",
       " 'sp.12',\n",
       " 'sp.13',\n",
       " 'sp.14',\n",
       " 'sp.15',\n",
       " 'sp.16',\n",
       " 'sp.17',\n",
       " 'sp.18',\n",
       " 'sp.19',\n",
       " 'sp.20',\n",
       " 'sp.21',\n",
       " 'sp.22',\n",
       " 'sp.23',\n",
       " 'sp.24',\n",
       " 'sp.25',\n",
       " 'stl1.1',\n",
       " 'stl1.2',\n",
       " 'stl1.3',\n",
       " 'stl1.4',\n",
       " 'stl1.5',\n",
       " 'stl1.6',\n",
       " 'stl1.7',\n",
       " 'stl1.8',\n",
       " 'stl1.9',\n",
       " 'stl1.10',\n",
       " 'stl1.11',\n",
       " 'stl1.12',\n",
       " 'stl1.13',\n",
       " 'stl1.14',\n",
       " 'stl1.15',\n",
       " 'stl1.16',\n",
       " 'stl1.17',\n",
       " 'stl1.18',\n",
       " 'stl1.19',\n",
       " 'stl1.20',\n",
       " 'stl1.21',\n",
       " 'stl1.22',\n",
       " 'stl1.23',\n",
       " 'stl1.24',\n",
       " 'stl1.25',\n",
       " 'u10.1',\n",
       " 'u10.2',\n",
       " 'u10.3',\n",
       " 'u10.4',\n",
       " 'u10.5',\n",
       " 'u10.6',\n",
       " 'u10.7',\n",
       " 'u10.8',\n",
       " 'u10.9',\n",
       " 'u10.10',\n",
       " 'u10.11',\n",
       " 'u10.12',\n",
       " 'u10.13',\n",
       " 'u10.14',\n",
       " 'u10.15',\n",
       " 'u10.16',\n",
       " 'u10.17',\n",
       " 'u10.18',\n",
       " 'u10.19',\n",
       " 'u10.20',\n",
       " 'u10.21',\n",
       " 'u10.22',\n",
       " 'u10.23',\n",
       " 'u10.24',\n",
       " 'u10.25',\n",
       " 'v10.1',\n",
       " 'v10.2',\n",
       " 'v10.3',\n",
       " 'v10.4',\n",
       " 'v10.5',\n",
       " 'v10.6',\n",
       " 'v10.7',\n",
       " 'v10.8',\n",
       " 'v10.9',\n",
       " 'v10.10',\n",
       " 'v10.11',\n",
       " 'v10.12',\n",
       " 'v10.13',\n",
       " 'v10.14',\n",
       " 'v10.15',\n",
       " 'v10.16',\n",
       " 'v10.17',\n",
       " 'v10.18',\n",
       " 'v10.19',\n",
       " 'v10.20',\n",
       " 'v10.21',\n",
       " 'v10.22',\n",
       " 'v10.23',\n",
       " 'v10.24',\n",
       " 'v10.25',\n",
       " 't2m.1',\n",
       " 't2m.2',\n",
       " 't2m.3',\n",
       " 't2m.4',\n",
       " 't2m.5',\n",
       " 't2m.6',\n",
       " 't2m.7',\n",
       " 't2m.8',\n",
       " 't2m.9',\n",
       " 't2m.10',\n",
       " 't2m.11',\n",
       " 't2m.12',\n",
       " 't2m.13',\n",
       " 't2m.14',\n",
       " 't2m.15',\n",
       " 't2m.16',\n",
       " 't2m.17',\n",
       " 't2m.18',\n",
       " 't2m.19',\n",
       " 't2m.20',\n",
       " 't2m.21',\n",
       " 't2m.22',\n",
       " 't2m.23',\n",
       " 't2m.24',\n",
       " 't2m.25',\n",
       " 'stl2.1',\n",
       " 'stl2.2',\n",
       " 'stl2.3',\n",
       " 'stl2.4',\n",
       " 'stl2.5',\n",
       " 'stl2.6',\n",
       " 'stl2.7',\n",
       " 'stl2.8',\n",
       " 'stl2.9',\n",
       " 'stl2.10',\n",
       " 'stl2.11',\n",
       " 'stl2.12',\n",
       " 'stl2.13',\n",
       " 'stl2.14',\n",
       " 'stl2.15',\n",
       " 'stl2.16',\n",
       " 'stl2.17',\n",
       " 'stl2.18',\n",
       " 'stl2.19',\n",
       " 'stl2.20',\n",
       " 'stl2.21',\n",
       " 'stl2.22',\n",
       " 'stl2.23',\n",
       " 'stl2.24',\n",
       " 'stl2.25',\n",
       " 'stl3.1',\n",
       " 'stl3.2',\n",
       " 'stl3.3',\n",
       " 'stl3.4',\n",
       " 'stl3.5',\n",
       " 'stl3.6',\n",
       " 'stl3.7',\n",
       " 'stl3.8',\n",
       " 'stl3.9',\n",
       " 'stl3.10',\n",
       " 'stl3.11',\n",
       " 'stl3.12',\n",
       " 'stl3.13',\n",
       " 'stl3.14',\n",
       " 'stl3.15',\n",
       " 'stl3.16',\n",
       " 'stl3.17',\n",
       " 'stl3.18',\n",
       " 'stl3.19',\n",
       " 'stl3.20',\n",
       " 'stl3.21',\n",
       " 'stl3.22',\n",
       " 'stl3.23',\n",
       " 'stl3.24',\n",
       " 'stl3.25',\n",
       " 'iews.1',\n",
       " 'iews.2',\n",
       " 'iews.3',\n",
       " 'iews.4',\n",
       " 'iews.5',\n",
       " 'iews.6',\n",
       " 'iews.7',\n",
       " 'iews.8',\n",
       " 'iews.9',\n",
       " 'iews.10',\n",
       " 'iews.11',\n",
       " 'iews.12',\n",
       " 'iews.13',\n",
       " 'iews.14',\n",
       " 'iews.15',\n",
       " 'iews.16',\n",
       " 'iews.17',\n",
       " 'iews.18',\n",
       " 'iews.19',\n",
       " 'iews.20',\n",
       " 'iews.21',\n",
       " 'iews.22',\n",
       " 'iews.23',\n",
       " 'iews.24',\n",
       " 'iews.25',\n",
       " 'inss.1',\n",
       " 'inss.2',\n",
       " 'inss.3',\n",
       " 'inss.4',\n",
       " 'inss.5',\n",
       " 'inss.6',\n",
       " 'inss.7',\n",
       " 'inss.8',\n",
       " 'inss.9',\n",
       " 'inss.10',\n",
       " 'inss.11',\n",
       " 'inss.12',\n",
       " 'inss.13',\n",
       " 'inss.14',\n",
       " 'inss.15',\n",
       " 'inss.16',\n",
       " 'inss.17',\n",
       " 'inss.18',\n",
       " 'inss.19',\n",
       " 'inss.20',\n",
       " 'inss.21',\n",
       " 'inss.22',\n",
       " 'inss.23',\n",
       " 'inss.24',\n",
       " 'inss.25',\n",
       " 'stl4.1',\n",
       " 'stl4.2',\n",
       " 'stl4.3',\n",
       " 'stl4.4',\n",
       " 'stl4.5',\n",
       " 'stl4.6',\n",
       " 'stl4.7',\n",
       " 'stl4.8',\n",
       " 'stl4.9',\n",
       " 'stl4.10',\n",
       " 'stl4.11',\n",
       " 'stl4.12',\n",
       " 'stl4.13',\n",
       " 'stl4.14',\n",
       " 'stl4.15',\n",
       " 'stl4.16',\n",
       " 'stl4.17',\n",
       " 'stl4.18',\n",
       " 'stl4.19',\n",
       " 'stl4.20',\n",
       " 'stl4.21',\n",
       " 'stl4.22',\n",
       " 'stl4.23',\n",
       " 'stl4.24',\n",
       " 'stl4.25',\n",
       " 'fsr.1',\n",
       " 'fsr.2',\n",
       " 'fsr.3',\n",
       " 'fsr.4',\n",
       " 'fsr.5',\n",
       " 'fsr.6',\n",
       " 'fsr.7',\n",
       " 'fsr.8',\n",
       " 'fsr.9',\n",
       " 'fsr.10',\n",
       " 'fsr.11',\n",
       " 'fsr.12',\n",
       " 'fsr.13',\n",
       " 'fsr.14',\n",
       " 'fsr.15',\n",
       " 'fsr.16',\n",
       " 'fsr.17',\n",
       " 'fsr.18',\n",
       " 'fsr.19',\n",
       " 'fsr.20',\n",
       " 'fsr.21',\n",
       " 'fsr.22',\n",
       " 'fsr.23',\n",
       " 'fsr.24',\n",
       " 'fsr.25',\n",
       " 'flsr.1',\n",
       " 'flsr.2',\n",
       " 'flsr.3',\n",
       " 'flsr.4',\n",
       " 'flsr.5',\n",
       " 'flsr.6',\n",
       " 'flsr.7',\n",
       " 'flsr.8',\n",
       " 'flsr.9',\n",
       " 'flsr.10',\n",
       " 'flsr.11',\n",
       " 'flsr.12',\n",
       " 'flsr.13',\n",
       " 'flsr.14',\n",
       " 'flsr.15',\n",
       " 'flsr.16',\n",
       " 'flsr.17',\n",
       " 'flsr.18',\n",
       " 'flsr.19',\n",
       " 'flsr.20',\n",
       " 'flsr.21',\n",
       " 'flsr.22',\n",
       " 'flsr.23',\n",
       " 'flsr.24',\n",
       " 'flsr.25',\n",
       " 'u100.1',\n",
       " 'u100.2',\n",
       " 'u100.3',\n",
       " 'u100.4',\n",
       " 'u100.5',\n",
       " 'u100.6',\n",
       " 'u100.7',\n",
       " 'u100.8',\n",
       " 'u100.9',\n",
       " 'u100.10',\n",
       " 'u100.11',\n",
       " 'u100.12',\n",
       " 'u100.13',\n",
       " 'u100.14',\n",
       " 'u100.15',\n",
       " 'u100.16',\n",
       " 'u100.17',\n",
       " 'u100.18',\n",
       " 'u100.19',\n",
       " 'u100.20',\n",
       " 'u100.21',\n",
       " 'u100.22',\n",
       " 'u100.23',\n",
       " 'u100.24',\n",
       " 'u100.25',\n",
       " 'v100.1',\n",
       " 'v100.2',\n",
       " 'v100.3',\n",
       " 'v100.4',\n",
       " 'v100.5',\n",
       " 'v100.6',\n",
       " 'v100.7',\n",
       " 'v100.8',\n",
       " 'v100.9',\n",
       " 'v100.10',\n",
       " 'v100.11',\n",
       " 'v100.12',\n",
       " 'v100.13',\n",
       " 'v100.14',\n",
       " 'v100.15',\n",
       " 'v100.16',\n",
       " 'v100.17',\n",
       " 'v100.18',\n",
       " 'v100.19',\n",
       " 'v100.20',\n",
       " 'v100.21',\n",
       " 'v100.22',\n",
       " 'v100.23',\n",
       " 'v100.24',\n",
       " 'v100.25']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset contains 5937 instances and 556 attributes (including \n",
    "# the outcome to be predicted)\n",
    "print data.shape\n",
    "data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below, data is going to be separated in train, validation, and test. Given that the use of Pandas dataframes is quite advanced, and doing this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indicesTrain = (np.where(data.year<=2006))[0]\n",
    "indicesVal = (np.where((data.year==2007) | (data.year==2008)))[0]\n",
    "indicesTest = (np.where(data.year>=2009))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware!, **indicesTrain** does not contain the training data, but the *indices* of the training data. For instance, the following cell means that training data is made of instance number 0, instance number 1, ..., up to instance number 2527. This will be important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2525, 2526, 2527])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicesTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to transform **data**, which is a Pandas dataframe, to **ava**, which is a NumPy matrix. The reason is that Scikit-learn uses NumPy matrices, not Panda dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ava = data.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **ava** is going to be decomposed into inputs **X** and outputs **y**. And then, into training, validation, and test. For instance, **Xava** and **yava** contain the input attributes, and the output attribute (**energy**) of the whole dataset. Please, ask yourself why the inputs use \"6:\" and the output use \"0\". **Xtrain** and **ytrain** are the same, but for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xava = ava[:,6:]; yava = ava[:,0]\n",
    "Xtrain = ava[indicesTrain,6:]; ytrain = ava[indicesTrain,0]\n",
    "Xval = ava[indicesVal,6:]; yval = ava[indicesVal,0]\n",
    "Xtest = ava[indicesTest,6:][:,6:]; ytest = ava[indicesTest,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following cell defines function **mae** (Mean Absolute Error), that we will use later to measure the accuracy of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mae(yval_pred, yval):\n",
    "  val_mae = metrics.mean_absolute_error(yval_pred, yval)\n",
    "  return(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trains KNN with (Xtrain, ytrain) and evaluates it with (Xval, yval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.7 ms, sys: 1.51 ms, total: 80.2 ms\n",
      "Wall time: 80.2 ms\n",
      "MAE for KNN with K=5 is 486.911414935\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "n_neighbors = 5\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "np.random.seed(0)\n",
    "%time _ = knn.fit(Xtrain, ytrain)\n",
    "yval_pred = knn.predict(Xval)\n",
    "\n",
    "print \"MAE for KNN with K=5 is {}\".format(mae(yval_pred, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case you need help for KNN\n",
    "# help('sklearn.neighbors.KNeighborsRegressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell, does hyper-parameter tuning for parameter K (n_neighbors), from 1 to 4 by 1. Please, notice that with **partitions = [(indicesTrain, indicesVal)]** we are telling **gridSearch** to use the training dataset for training the different models with the different parameters, and the validation dataset for testing. Notice that this is different to other notebooks, where crossvalidation was used for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n",
      "CPU times: user 2.01 s, sys: 90.4 ms, total: 2.1 s\n",
      "Wall time: 2.36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "np.random.seed(0)\n",
    "param_grid = {'n_neighbors': range(1,4,1)}\n",
    "\n",
    "partitions = [(indicesTrain, indicesVal)]\n",
    "clf = GridSearchCV(neighbors.KNeighborsRegressor(), \n",
    "                   param_grid,\n",
    "                   scoring='mean_absolute_error',\n",
    "                   cv=partitions , verbose=1)\n",
    "%time _ = clf.fit(Xava,yava)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we show the best K parameter and the MAE of the final model built with the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K: {'n_neighbors': 3} and MAE for best K: 503.711691044\n"
     ]
    }
   ],
   "source": [
    "print \"Best K: {} and MAE for best K: {}\".format(clf.best_params_, -clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. HOW LONG DOES IT TAKE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to have some estimation of how long your machine learning algorithm is going to take. In the next two cells, try to estimate how many seconds KNN (with K=3) does it take, with only **100 instances**. With 6000 instances, it will take approximately 60 times that number. You can use **%time** for timing, as in previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 ms, sys: 570 µs, total: 2.99 ms\n",
      "Wall time: 3.01 ms\n",
      "MAE for KNN with K=3 is 517.622707211\n"
     ]
    }
   ],
   "source": [
    "# Timing KNN\n",
    "\n",
    "n_neighbors = 3\n",
    "Xtrain_100 = ava[:100,6:]; ytrain_100 = ava[:100,0]\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = knn.fit(Xtrain_100, ytrain_100)\n",
    "\n",
    "yval_pred_knn = knn.predict(Xval)\n",
    "print \"MAE for KNN with K=3 is {}\".format(mae(yval_pred_knn, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, do the same for Decision trees with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.8 ms, sys: 1.87 ms, total: 51.7 ms\n",
      "Wall time: 72.8 ms\n",
      "MAE with decision trees is 468.927036182\n"
     ]
    }
   ],
   "source": [
    "# Timing Decision trees\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = clf.fit(Xtrain_100, ytrain_100)\n",
    "\n",
    "yval_pred_clf = clf.predict(Xval)\n",
    "print \"MAE with decision trees is {}\".format(mae(yval_pred_clf, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MODEL SELECTION AND HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a KNN model with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions [!!!]\n",
    "\n",
    "- Do we train the model with the Train partition and then apply it to the Test partition or do we do CV in the Grid Search??\n",
    "- *Can you improve the results?* With respect to what??\n",
    "- GridSearch to optimize which parameters?? (We have K for KNN and depth for Tree Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 213 µs, total: 84.2 ms\n",
      "Wall time: 84.3 ms\n",
      "MAE for KNN with K=5 is 503.711691044\n"
     ]
    }
   ],
   "source": [
    "# Train KNN \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "knn_reg.fit(Xtrain, ytrain) \n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = knn.fit(Xtrain, ytrain)\n",
    "\n",
    "yval_pred_knn = knn.predict(Xval)\n",
    "print \"MAE for KNN with K=\" + str(knn_reg.n_neighbors) + \" is {}\".format(mae(yval_pred_knn, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for KNN. Can you improve results? Note: if **gridSearch** takes too long, you can use **Randomized Search** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.7 s, sys: 849 ms, total: 34.6 s\n",
      "Wall time: 38.3 s\n",
      "The optimal value of K obtained with Grid Search is: {'n_neighbors': 19} with MAE 469.824689374\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameter tuning for KNN with gridSearch\n",
    "\n",
    "param_k_grid = {'n_neighbors': list(range(1,20))}\n",
    "\n",
    "knn_grid = GridSearchCV(KNeighborsRegressor(), \n",
    "                   param_k_grid,\n",
    "                   scoring='mean_absolute_error',\n",
    "                   cv=10, n_jobs=1)\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = knn_grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print \"The optimal value of K obtained with Grid Search is: \" + str(knn_grid.best_params_) + \" with MAE \" + str(-knn_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree for regression with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 22.8 ms, total: 2.71 s\n",
      "Wall time: 2.96 s\n",
      "MAE with decision trees is 371.829430331\n"
     ]
    }
   ],
   "source": [
    "# Train a decision tree for regression\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = clf.fit(Xtrain, ytrain)\n",
    "\n",
    "yval_pred_clf = clf.predict(Xval)\n",
    "print \"MAE with decision trees is {}\".format(mae(yval_pred_clf, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for Decision trees. Can you improve results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter regression for estimator DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n           splitter='best'). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c9f34c33bf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time _ = clf_grid.fit(Xtrain, ytrain)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"The optimal value of trees obtained with Grid Search is: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" with MAE \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclf_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    259\u001b[0m                                      \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                                      \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                                      (name, self))\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0msub_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0msub_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0msub_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter regression for estimator DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n           splitter='best'). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# DOES NOT WORK\n",
    "# Hyper-parameter tuning for Decision trees\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#help('sklearn.tree.DecisionTreeRegressor')\n",
    "\n",
    "param_grid = {'regression__max_depth': list(range(1,20))}\n",
    "\n",
    "clf_grid = GridSearchCV(DecisionTreeRegressor(), \n",
    "                   param_grid,\n",
    "                   scoring='mean_absolute_error',\n",
    "                   cv=10, n_jobs=1)\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = clf_grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print \"The optimal value of trees obtained with Grid Search is: \" + str(clf_grid.best_params_) + \" with MAE \" + str(-clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Random Forest (RF) with default parameters. A RF is an ensemble technique based on Decision Trees, but instead of training just a single decision tree, it trains many of them and then computes the average of the outputs. Please, bear in mind that a RF with default parameters involves training 100 trees. You can estimate by hand how long it is going to take, and if it is excessive, you can lower the number of decision trees in the ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 177 ms, total: 16.4 s\n",
      "Wall time: 22 s\n",
      "MAE for Random Forest is 503.711691044\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# help('sklearn.ensemble.RandomForestRegressor')\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = rf.fit(Xtrain, ytrain)\n",
    "\n",
    "yval_pred_rf = rf.predict(Xval)\n",
    "print \"MAE for Random Forest is {}\".format(mae(yval_pred_rf, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for Random Forests. Their main hyper-parameter is **n_estimators**, which is the number of decision trees in the ensemble. Check some values around the default value (like, 50, 100, 150, ...). Please, bear in mind this is going to take time ... In case you want to use other hyper-parameters, please ask the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hyper-parameter tuning for Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# help('sklearn.ensemble.RandomForestRegressor')\n",
    "\n",
    "param_estimators_grid = {'n_estimators': list(range(50,200,50))}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), \n",
    "                   param_estimators_grid,\n",
    "                   scoring='mean_absolute_error',\n",
    "                   cv=10, n_jobs=1)\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = rf_grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print \"The optimal number of estimators in Grid Search is: \" + str(rf_grid.best_params_) + \" with MAE \" + str(-rf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Gradient Tree Boosting (GB) with default parameters. A GB is also an ensemble technique based on Decision Trees. In this case, the second decision tree tries to fix the mistakes of the first decision tree. The third decision tree tries to fix the mistakes of the first two decision trees. An so on.\n",
    "\n",
    "Please, bear in mind that a GB with default parameters involves training 100 trees. You can estimate by hand how long it is going to take, and if it is excessive, you can lower the number of decision trees in the ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a Gradient Tree Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "# help('sklearn.ensemble.GradientBoostingRegressor')\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = gb.fit(Xtrain, ytrain)\n",
    "\n",
    "yval_pred_gb = gb.predict(Xval)\n",
    "print \"MAE for Gradient Tree Boosting is {}\".format(mae(yval_pred_gb, yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyper-parameter tuning for Gradient Boosting. Their main hyper-parameter is **n_estimators**, which is the number of decision trees in the ensemble. Check some values around the default value (like, 50, 100, 150, ...). Please, bear in mind this is going to take time ... In case you want to use other hyper-parameters, please ask the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper-parameter tuning for Gradient Tree Boosting\n",
    "\n",
    "\n",
    "param_estimators_grid = {'n_estimators': list(range(50,150,50))}\n",
    "\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), \n",
    "                   param_estimators_grid,\n",
    "                   scoring='mean_absolute_error',\n",
    "                   cv=10, n_jobs=1)\n",
    "\n",
    "np.random.seed(0)\n",
    "%time _ = gb_grid.fit(Xtrain, ytrain)\n",
    "\n",
    "print \"The optimal number of estimators Grid Search is: \" + str(gb_grid.best_params_) + \" with MAE \" + str(-gb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should know which model performs best, and what hyper-parameters to use. Please, evaluate that best performing model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<WRITE CODE HERE FOR BEST MODEL EVALUATION ON THE TEST SET>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This section is more open-ended than the previous ones, and I offer less guidance. It is definitely harder, but you can always ask the teacher. \n",
    "\n",
    "You have to answer the following question: \n",
    "\n",
    "- \"Are all 550 input attributes actually necessary in order to get a good model? Is it possible to have an accurate model that uses fewer than 550 variables? How many? Is it enough to have the attributes for the actual Sotavento location? (13th in the grid)\"\n",
    "\n",
    "In order to answer this question:\n",
    "\n",
    "1) Go through the \"Attribute Selection\" ipython notebook, and understand the main ideas about **SelectKBest** and **Pipeline**.\n",
    "\n",
    "2) Use **SelectKBest** and **Pipeline** (and whatever else you need) in order to find a subset of attributes that allows to build an accurate Decision Tree model. We are going to use here Decision Trees because they are faster (even if Random Forests or Gradient Boosting performed better in previous sections). Please, note that you cannot just copy/paste from the \"Attribute Selection\" notebook. You will have to think about how to use the main ideas from that notebook, and change whatever needs changing. \n",
    "\n",
    "3) Once you have decided which attributes should be used for the Decision Tree, evaluate the final model on the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#<USE AS MANY CELLS AS YOU NEED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
